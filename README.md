# TRABALHO DE INTELIG√äNCIA ARTIFICIAL ‚Äì A2 (PORTUGU√äS)

Alunos participantes:
- EDGAR DE SOUZA DIAS  
- JO√ÉO EMANUEL MENDON√áA AP√ìSTOLO  
- JOS√â MATHEUS RIBEIRO DOS SANTOS  
- MARIA EDUARDA PIRES POSSARI DOS SANTOS  
- ULISSES DE JESUS CAVALCANTE

Trabalho desenvolvido como forma de avalia√ß√£o (A2) para a disciplina de Intelig√™ncia Artificial - COMP0427
Universidade Federal de Sergipe | Departamento de Computa√ß√£o | Prof. Dr. Hendrik Teixeira Macedo

## Objetivo do Projeto

Este trabalho tem como objetivo explorar a capacidade de modelos multimodais de Intelig√™ncia Artificial (OpenAI ChatGPT-4o e Google Gemini Pro) em compreender e gerar descri√ß√µes coerentes com base em imagens, √°udios e textos narrativos associados. Tal investiga√ß√£o ser√° feita por meio de tr√™s experimentos. Primeiramente, ser√° a capacidade dos modelos de lidarem com uma entrada multimodal. Subsequentemente, a transfer√™ncia de modalidade ser√° avaliada. Por fim, ser√° aferida a capacidade das arquiteturas de reconhecer o contexto de v√°rios prompts.

## Funcionalidades

- Convers√£o de descri√ß√µes de texto em √°udio via TTS (text-to-speech) com OpenAI e gTTS (Google Text-to-Speech) com Gemini
- Transcri√ß√£o de √°udios narrativos com Vosk (speech-to-text)
- An√°lise de imagens com descri√ß√£o de contexto via:
  - OpenAI GPT-4o
  - Google Gemini 1.5 Pro
- Compara√ß√£o entre os modelos em termos de:
  - **Coer√™ncia textual**
  - **Acur√°cia multimodal**
  - **Tempo de resposta**
- Avalia√ß√£o da capacidade dos modelos de lidarem com entrada multimodal
- Avalia√ß√£o da transfer√™ncia de modadelidade
- Avalia√ß√£o da progress√£o narrativa com base nas descri√ß√µes geradas

## Tecnologias Utilizadas

- **Python 3.10+**
- **OpenAI API (GPT-4o, TTS)**
- **Google Gemini API (Gemini 1.5 Pro, gTTS)**
- **Vosk (Reconhecimento de fala offline)**
- **gTTS e pydub** para manipula√ß√£o de √°udio
- **Pillow (PIL)** para tratamento de imagens
- **Google Drive** para organiza√ß√£o dos dados

> [!IMPORTANT]
> Para a utiliza√ß√£o das APIs do OpenAI ChatGPT e do Google Gemini, s√£o necess√°rias chaves secretas que permitem o acesso a estes recursos.
> 
> A chave do Gemini pode ser obtida gratuitamente pelo Google, por√©m a chave do ChatGPT-4o s√≥ pode ser obtida mediante um investimento financeiro no pr√≥prio site da OpenAI.

**Depois que as chaves forem obtidas, elas devem ser postas na aba "Secrets" do Google Colab e importadas para o c√≥digo utilizando:**
```python
from google.colab import userdata

openai_api_key = userdata.get('OPENAI_API_KEY')  # Chave da OpenAI
google_api_key = userdata.get('GOOGLE_API_KEY')  # Chave do Google
```

## Estrutura de Pastas

üìÅ Intelig√™ncia Artificial/ 

  ‚îú‚îÄ‚îÄ üìÅ Audios_narrativa/ # √Åudios .mp3 com narra√ß√£o descritiva de cada imagem 
  
  ‚îú‚îÄ‚îÄ üìÅ Imagens_narrativa/ # Conjunto de imagens usadas no experimento 
  
  ‚îú‚îÄ‚îÄ üìÑ IA_Trabalho_A2.ipynb # C√≥digo principal do projeto 
  
  ‚îú‚îÄ‚îÄ üìÑ README.md # Documenta√ß√£o do projeto


## Como Executar

1. **Monte o Google Drive no Colab** e garanta que os caminhos estejam corretos:
```python
from google.colab import drive
drive.mount('/content/drive')
```

2. Execute o notebook passo a passo, garantindo:
- Convers√£o dos arquivos .mp3 para .wav (PCM 16kHz mono)
- Transcri√ß√£o dos √°udios com Vosk
- Gera√ß√£o de descri√ß√µes com OpenAI e Gemini
- Avalia√ß√£o de coer√™ncia e tempo

> [!CAUTION]
> Cada √°udio presente em "Audios_narrativa" se relaciona diretamente com uma imagem em "Imagens_narrativas". A sequ√™ncia √© a seguinte:
> 
> audio_1.mp3: Tobias explorando o bairro.jpg
> 
> audio_2.mp3: Tobias achou o guarda-chuva azul.jpg
> 
> audio_3.mp3: Guarda-chuva se fecha e portal aparece.jpg
> 
> audio_4.mp3: Tobias √© sugado pelo portal.jpg
> 
> audio_5.mp3: Tobias chega em Umbrel√≥polis e √© recebido pelo coelho estiloso.jpg

> [!NOTE]
> As imagens utilizadas no terceiro experimento foram geradas pelo ChatGPT-4o a partir da seguinte narrativa:
> 
> Num dia em que o sol brilhava com for√ßa, um gato cinza chamado Tobias decidiu sair para explorar o bairro. Ele andava como se tivesse um compromisso s√©rio ‚Äî cauda erguida, passos firmes. No meio do caminho, encontrou algo incomum: um guarda-chuva azul, aberto, no meio da cal√ßada. Tobias parou. Olhou para o guarda-chuva. Depois para o c√©u sem nuvens. ‚ÄúHumano distra√≠do‚Äù, pensou ele. Mas ao tocar no guarda-chuva com a pata, ele se fechou de repente... e um portal se abriu! Tobias foi sugado para dentro com um miau! surpreso. Quando abriu os olhos, estava numa cidade onde todos os animais usavam roupas e andavam de patinete. Um coelho de √≥culos escuros o olhou e disse: ‚Äî Seja bem-vindo a Umbrell√≥polis. Aqui, s√≥ entra quem encontra o Guarda-Chuva Azul. Tobias deu um miado resignado. Aparentemente, a aventura do dia estava s√≥ come√ßando.

## M√©tricas Avaliadas

| M√©trica              | Descri√ß√£o                                                                 |
|----------------------|---------------------------------------------------------------------------|
| Coer√™ncia Textual    | Avaliada manualmente pelos autores do projeto (nota de 1 a 5)             |
| Acur√°cia Multimodal  | Compara√ß√£o entre a transcri√ß√£o real da narrativa e a descri√ß√£o gerada     |
| Tempo de Resposta    | Tempo medido em segundos para a gera√ß√£o da resposta de cada modelo        |


# ARTIFICIAL INTELLIGENCE PROJECT ‚Äì A2 (ENGLISH)

Participating Students:
- EDGAR DE SOUZA DIAS  
- JO√ÉO EMANUEL MENDON√áA AP√ìSTOLO  
- JOS√â MATHEUS RIBEIRO DOS SANTOS  
- MARIA EDUARDA PIRES POSSARI DOS SANTOS  
- ULISSES DE JESUS CAVALCANTE

Work developed as part of the A2 evaluation for the Artificial Intelligence course - COMP0427  
Federal University of Sergipe | Department of Computing | Prof. Dr. Hendrik Teixeira Macedo

## Project Objective

This project aims to explore the capabilities of multimodal Artificial Intelligence models (OpenAI ChatGPT-4o and Google Gemini Pro) in understanding and generating coherent descriptions based on images, audio, and associated narrative texts. This investigation will be conducted through three experiments. First, we will evaluate the models' ability to handle multimodal input. Then, modality transfer will be assessed. Finally, we will evaluate the architectures' capability to recognize the context of multiple prompts.

## Features

- Conversion of text descriptions to audio using TTS (text-to-speech) with OpenAI and gTTS (Google Text-to-Speech) with Gemini
- Transcription of narrative audios using Vosk (speech-to-text)
- Image analysis with contextual description via:
  - OpenAI GPT-4o
  - Google Gemini 1.5 Pro
- Comparison between the models in terms of:
  - **Textual coherence**
  - **Multimodal accuracy**
  - **Response time**
- Evaluation of the models' ability to handle multimodal input
- Evaluation of modality transfer
- Assessment of narrative progression based on generated descriptions

## Technologies Used

- **Python 3.10+**
- **OpenAI API (GPT-4o, TTS)**
- **Google Gemini API (Gemini 1.5 Pro, gTTS)**
- **Vosk (Offline speech recognition)**
- **gTTS and pydub** for audio manipulation
- **Pillow (PIL)** for image processing
- **Google Drive** for data organization

> [!IMPORTANT]
> To use the OpenAI ChatGPT and Google Gemini APIs, secret keys are required to access these resources.
> 
> The Gemini key can be obtained for free from Google, but the ChatGPT-4o key can only be acquired through a financial investment on OpenAI's official website.

**After obtaining the keys, they must be placed in the "Secrets" tab of Google Colab and imported into the code using:**
```python
from google.colab import userdata

openai_api_key = userdata.get('OPENAI_API_KEY')  # OpenAI's Key
google_api_key = userdata.get('GOOGLE_API_KEY')  # Google's Key
```

## Folder Structure

üìÅ Artificial Intelligence/  

  ‚îú‚îÄ‚îÄ üìÅ Audios_narrativa/ # .mp3 audio files with descriptive narration for each image  
  
  ‚îú‚îÄ‚îÄ üìÅ Imagens_narrativa/ # Set of images used in the experiment  
  
  ‚îú‚îÄ‚îÄ üìÑ IA_Trabalho_A2.ipynb # Main project code  
  
  ‚îú‚îÄ‚îÄ üìÑ README.md # Project documentation

## How to Run

1. **Mount Google Drive in Colab** and ensure the paths are correct:
```python
from google.colab import drive
drive.mount('/content/drive')
```

2. Run the notebook step by step, ensuring:
- Conversion of .mp3 files to .wav (PCM 16kHz mono)
- Audio transcription with Vosk
- Generation of descriptions with OpenAI and Gemini
- Evaluation of coherence and response time

> [!CAUTION]
> Each audio file in "Audios_narrativa" is directly related to an image in "Imagens_narrativas". The sequence is as follows:
> 
> audio_1.mp3: Tobias explorando o bairro.jpg
> 
> audio_2.mp3: Tobias achou o guarda-chuva azul.jpg
> 
> audio_3.mp3: Guarda-chuva se fecha e portal aparece.jpg
> 
> audio_4.mp3: Tobias √© sugado pelo portal.jpg
> 
> audio_5.mp3: Tobias chega em Umbrel√≥polis e √© recebido pelo coelho estiloso.jpg

> [!NOTE]
> The images used in the third experiment were generated by ChatGPT-4o, using the following narrative as a source:
> 
> On a day when the sun was shining brightly, a gray cat named Tobias decided to explore the neighborhood. He walked as if he had an important appointment ‚Äî tail up, steps confident. Along the way, he found something unusual: a blue umbrella, open, in the middle of the sidewalk. Tobias stopped. He looked at the umbrella. Then up at the cloudless sky. ‚ÄúCareless human,‚Äù he thought. But when he touched the umbrella with his paw, it suddenly closed... and a portal opened! Tobias was sucked inside with a surprised meow! When he opened his eyes, he was in a city where all the animals wore clothes and rode scooters. A rabbit with sunglasses looked at him and said: ‚Äî Welcome to Umbrellopolis. Here, only those who find the Blue Umbrella may enter. Tobias let out a resigned meow. Apparently, the day's adventure was just beginning.

## Evaluated Metrics

| M√©trica              | Descri√ß√£o                                                                           |
|----------------------|-------------------------------------------------------------------------------------|
| Textual Coherence    | Manually evaluated by the project authors (score from 1 to 5)                       |
| Multimodal Accuracy  | Comparison between the actual narrative transcription and generated description     |
| Response Time        | Time measured in seconds for each model's response generation                       |
